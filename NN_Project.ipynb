{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davemkhitaryan/NN-Semester-Project/blob/main/NN_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSmQuKhl-ukD"
      },
      "source": [
        "# Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlCcdGMqan70"
      },
      "source": [
        "pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRk7ia3Rjz-d"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from numpy import array\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from matplotlib import pyplot\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb1o8ubiG3vz"
      },
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "print('Installing dependencies...')\n",
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip install -qU pyfluidsynth pretty_midi\n",
        "\n",
        "!pip install -qU magenta\n",
        "\n",
        "# Hack to allow python to pick up the newly-installed fluidsynth lib. \n",
        "# This is only needed for the hosted Colab environment.\n",
        "import ctypes.util\n",
        "orig_ctypes_util_find_library = ctypes.util.find_library\n",
        "def proxy_find_library(lib):\n",
        "  if lib == 'fluidsynth':\n",
        "    return 'libfluidsynth.so.1'\n",
        "  else:\n",
        "    return orig_ctypes_util_find_library(lib)\n",
        "ctypes.util.find_library = proxy_find_library\n",
        "\n",
        "print('Importing libraries and defining some helper functions...')\n",
        "from google.colab import files\n",
        "\n",
        "import magenta\n",
        "import note_seq\n",
        "import tensorflow\n",
        "\n",
        "print('ðŸŽ‰ Done!')\n",
        "print(magenta.__version__)\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTc_7d3F_VMZ"
      },
      "source": [
        "# The Training and Testing Data\n",
        "In the cells below we create the training and testing data. Including dividing the songs into both categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LBuRbYTtxxY"
      },
      "source": [
        "#generate simplified version\n",
        "def simplify_song(song):\n",
        "  simplified_song = []\n",
        "  for i in range(len(song)):\n",
        "    #bar = []\n",
        "    for j in range(8):\n",
        "      if song[i][j] == 2:\n",
        "        #bar.append(1)\n",
        "        simplified_song.append(1)\n",
        "      else:\n",
        "        #bar.append(0)\n",
        "        simplified_song.append(0)\n",
        "\n",
        "    #simplified_song.append(bar)\n",
        "  return simplified_song  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5aIaexKc47P"
      },
      "source": [
        "#Chorus of Under Pressure by Queen\n",
        "#We also took the kick/bass drum here\n",
        "queen_under_pressure = []\n",
        "\n",
        "queen_under_pressure.append([2,2,2,2,2,2,2,2])#28\n",
        "queen_under_pressure.append([2,2,2,2,2,2,2,2])\n",
        "queen_under_pressure.append([2,2,2,2,2,2,2,2])\n",
        "queen_under_pressure.append([2,2,2,2,2,2,2,2])\n",
        "queen_under_pressure.append([2,2,2,2,2,2,2,2])\n",
        "queen_under_pressure.append([2,2,2,2,2,2,0,2])\n",
        "queen_under_pressure.append([2,0,0,0,0,0,0,0])\n",
        "queen_under_pressure.append([2,1,1,2,0,0,0,0])\n",
        "\n",
        "print(queen_under_pressure)\n",
        "\n",
        "queen_up_simplified = simplify_song(queen_under_pressure)\n",
        "queen_up_simplified = np.array(queen_up_simplified)\n",
        "print(queen_up_simplified)\n",
        "file = open('training_data/queen_up.txt', 'w')\n",
        "file.write(str(queen_up_simplified))\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE2lte-I1pEm"
      },
      "source": [
        "\n",
        "#8 eight-notes in one bar\n",
        "# 2 means the note is hit, 1 means it's still playing (to represent half and quart notes), 0 means nothing is played\n",
        "#we represent this by the kick/bass drum\n",
        "#Chorus of Bon jovi it's my life\n",
        "bon_jovi__its_my_life = []\n",
        "\n",
        "#chorus\n",
        "bon_jovi__its_my_life.append([2,0,0,0,2,0,0,0])\n",
        "bon_jovi__its_my_life.append([2,0,0,0,2,0,0,0])\n",
        "bon_jovi__its_my_life.append([2,0,0,0,2,0,0,0])\n",
        "bon_jovi__its_my_life.append([2,0,0,0,2,0,0,0])\n",
        "bon_jovi__its_my_life.append([2,0,0,0,2,0,0,0])\n",
        "bon_jovi__its_my_life.append([2,0,0,0,2,2,0,0])\n",
        "bon_jovi__its_my_life.append([2,0,0,0,2,0,0,0])\n",
        "bon_jovi__its_my_life.append([2,0,0,0,2,2,0,0])\n",
        "bon_jovi__its_my_life.append([2,0,0,0,2,0,0,0])\n",
        "bon_jovi__its_my_life.append([2,0,0,0,2,0,0,0])\n",
        "bon_jovi__its_my_life.append([2,0,0,0,2,0,0,0])\n",
        "bon_jovi__its_my_life.append([2,0,0,0,2,0,0,0])\n",
        "bon_jovi__its_my_life.append([2,0,0,0,2,0,0,0])\n",
        "bon_jovi__its_my_life.append([2,0,0,0,2,2,0,0])\n",
        "bon_jovi__its_my_life.append([2,0,0,0,2,0,0,0])\n",
        "bon_jovi__its_my_life.append([2,0,0,0,2,2,0,0])\n",
        "\n",
        "print(bon_jovi__its_my_life)\n",
        "\n",
        "bj_iml_updated = simplify_song(bon_jovi__its_my_life)\n",
        "bj_iml_updated = np.array(bj_iml_updated)\n",
        "print(bj_iml_updated)\n",
        "file = open('training_data/bj_iml.txt', 'w')\n",
        "file.write(str(bj_iml_updated))\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KSmkYFLETx6"
      },
      "source": [
        "#Chorus of eye of the tiger by survivor\n",
        "survivor_eyeofthetiger = []\n",
        "survivor_eyeofthetiger.append([2,0,2,0,2,0,2,0])\n",
        "survivor_eyeofthetiger.append([2,0,2,0,2,0,2,0])\n",
        "survivor_eyeofthetiger.append([2,0,2,0,2,0,2,0])\n",
        "survivor_eyeofthetiger.append([2,0,2,0,2,0,2,0])\n",
        "survivor_eyeofthetiger.append([2,0,2,0,2,0,2,0])\n",
        "survivor_eyeofthetiger.append([2,0,2,0,2,0,2,0])\n",
        "survivor_eyeofthetiger.append([2,0,2,0,2,0,2,0])\n",
        "survivor_eyeofthetiger.append([1,0,1,0,2,1,0,0])\n",
        "survivor_eyeofthetiger.append([2,1,2,1,2,1,2,1])\n",
        "survivor_eyeofthetiger.append([2,1,2,1,2,1,2,0])\n",
        "survivor_eyeofthetiger.append([2,0,2,0,2,0,2,0])\n",
        "survivor_eyeofthetiger.append([2,0,2,0,2,0,2,0])\n",
        "\n",
        "eyeofthetiger_simplified = simplify_song(survivor_eyeofthetiger)\n",
        "eyeofthetiger_simplified = np.array(eyeofthetiger_simplified)\n",
        "print(eyeofthetiger_simplified)\n",
        "file = open('training_data/survivor_eott.txt', 'w')\n",
        "file.write(str(eyeofthetiger_simplified))\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odejJcTm7j1x"
      },
      "source": [
        "#Chorus of R U Mine? by arctic monkeys\n",
        "arctic_rumine = []\n",
        "arctic_rumine.append([2,2,0,2,0,2,0,2])\n",
        "arctic_rumine.append([2,2,0,2,0,2,0,2])\n",
        "arctic_rumine.append([2,0,2,2,2,2,0,2])\n",
        "arctic_rumine.append([0,2,0,2,2,2,0,0])\n",
        "arctic_rumine.append([2,0,2,0,0,0,0,0])\n",
        "arctic_rumine.append([2,2,0,2,0,2,0,2])\n",
        "arctic_rumine.append([2,2,0,2,0,2,0,2])\n",
        "arctic_rumine.append([2,2,0,2,0,2,0,2])\n",
        "arctic_rumine.append([2,2,0,2,0,2,0,2])\n",
        "arctic_rumine.append([2,2,0,0,0,0,0,0])\n",
        "arctic_rumine.append([2,2,0,2,0,2,0,2])\n",
        "arctic_rumine.append([2,2,0,2,0,0,0,0])\n",
        "arctic_rumine.append([2,2,0,2,0,2,0,2])\n",
        "arctic_rumine.append([2,2,0,2,1,1,2,0])\n",
        "\n",
        "arctic_rumine_simplified = simplify_song(arctic_rumine)\n",
        "arctic_rumine_simplified = np.array(arctic_rumine_simplified)\n",
        "file = open('training_data/arctic_rumine.txt', 'w')\n",
        "file.write(str(arctic_rumine_simplified))\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-IZufQdEn2F"
      },
      "source": [
        "#Chorus of the take over, the breaks over by fall out boy\n",
        "fob_takeover_breaksover = []\n",
        "fob_takeover_breaksover.append([2,1,0,2,0,2,0,0])\n",
        "fob_takeover_breaksover.append([2,2,0,0,2,1,0,0])\n",
        "fob_takeover_breaksover.append([2,1,0,2,0,2,0,0])\n",
        "fob_takeover_breaksover.append([2,2,0,0,0,0,0,0])\n",
        "\n",
        "fob_takeover_breaksover.append([2,1,0,2,0,2,0,0])\n",
        "fob_takeover_breaksover.append([2,2,0,0,2,1,0,0])\n",
        "fob_takeover_breaksover.append([2,1,0,2,0,2,0,0])\n",
        "fob_takeover_breaksover.append([2,2,0,2,0,0,0,2])\n",
        "\n",
        "fob_takeover_breaksover.append([2,0,0,2,0,2,0,2])\n",
        "fob_takeover_breaksover.append([2,2,0,2,2,0,2,1])\n",
        "fob_takeover_breaksover.append([2,0,0,2,0,2,0,2])\n",
        "fob_takeover_breaksover.append([2,2,0,2,0,0,0,0])\n",
        "fob_takeover_breaksover.append([0,2,0,2,2,1,0,0])\n",
        "\n",
        "fob_takeover_breaksover_simplified = simplify_song(fob_takeover_breaksover)\n",
        "fob_takeover_breaksover_simplified = np.array(fob_takeover_breaksover_simplified)\n",
        "file = open('training_data/fob_totbo.txt', 'w')\n",
        "file.write(str(fob_takeover_breaksover_simplified))\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVisQPIbGCwm"
      },
      "source": [
        "#Chorus of this is how you remind me by Nickelback\n",
        "nickelback_tihyrm = []\n",
        "nickelback_tihyrm.append([2,1,0,0,2,2,0,0])\n",
        "nickelback_tihyrm.append([2,1,0,0,2,2,0,0])\n",
        "nickelback_tihyrm.append([2,1,0,0,2,2,0,0])\n",
        "nickelback_tihyrm.append([2,1,0,0,2,2,0,0])\n",
        "\n",
        "nickelback_tihyrm.append([2,2,0,0,2,2,0,0])\n",
        "nickelback_tihyrm.append([2,1,0,0,2,2,0,0])\n",
        "nickelback_tihyrm.append([2,1,0,0,2,2,0,0])\n",
        "nickelback_tihyrm.append([2,0,2,0,2,2,0,2])\n",
        "\n",
        "nickelback_tihyrm.append([2,1,0,0,2,2,0,0])\n",
        "nickelback_tihyrm.append([2,1,0,0,2,2,0,2])\n",
        "nickelback_tihyrm.append([2,1,0,0,2,2,0,0])\n",
        "nickelback_tihyrm.append([2,2,0,0,2,2,2,2]) #this one was difficult to translate\n",
        "\n",
        "nickelback_tihyrm_simplified = simplify_song(nickelback_tihyrm)\n",
        "nickelback_tihyrm_simplified = np.array(nickelback_tihyrm_simplified)\n",
        "file = open('training_data/nickelback_tihyrm.txt', 'w')\n",
        "file.write(str(nickelback_tihyrm_simplified))\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XxbBmlDoJDq"
      },
      "source": [
        "# chorus of Mr. Brightside by The Killers\n",
        "killers_brightside = []\n",
        "killers_brightside.append([2,0,0,0,2,0,0,2])\n",
        "killers_brightside.append([2,0,0,0,2,0,0,0])\n",
        "killers_brightside.append([2,0,0,0,2,0,0,0])\n",
        "killers_brightside.append([2,0,0,0,2,0,0,2])\n",
        "killers_brightside.append([2,0,0,0,2,0,0,0])\n",
        "killers_brightside.append([2,0,0,0,2,0,0,0])\n",
        "killers_brightside.append([2,0,0,0,2,0,0,2])\n",
        "killers_brightside.append([2,0,0,0,2,0,0,2])\n",
        "# repeat once\n",
        "killers_brightside.append([2,0,0,0,2,0,0,2])\n",
        "killers_brightside.append([2,0,0,0,2,0,0,0])\n",
        "killers_brightside.append([2,0,0,0,2,0,0,0])\n",
        "killers_brightside.append([2,0,0,0,2,0,0,2])\n",
        "killers_brightside.append([2,0,0,0,2,0,0,0])\n",
        "killers_brightside.append([2,0,0,0,2,0,0,0])\n",
        "killers_brightside.append([2,0,0,0,2,0,0,2])\n",
        "killers_brightside.append([2,0,0,0,2,0,0,2])\n",
        "\n",
        "brightside_simplified = simplify_song(killers_brightside)\n",
        "brightside_simplified = np.array(brightside_simplified)\n",
        "file = open('training_data/killers_brighside.txt', 'w')\n",
        "file.write(str(brightside_simplified))\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrHOn8jIox-y"
      },
      "source": [
        "# Chorus of Summer of 69 by Bryan Adams\n",
        "brian_adams_summer_69 = []\n",
        "brian_adams_summer_69.append([2,0,0,0,0,0,0,2])\n",
        "brian_adams_summer_69.append([2,0,0,0,2,0,0,2])\n",
        "brian_adams_summer_69.append([2,0,0,0,0,0,0,2])\n",
        "brian_adams_summer_69.append([2,0,0,0,2,0,0,2])\n",
        "brian_adams_summer_69.append([2,0,0,0,0,0,0,2])\n",
        "brian_adams_summer_69.append([2,0,0,0,2,0,0,2])\n",
        "brian_adams_summer_69.append([2,0,0,0,0,0,0,2])\n",
        "brian_adams_summer_69.append([2,0,0,0,2,0,0,2])\n",
        "brian_adams_summer_69.append([2,0,0,0,0,0,0,2])\n",
        "brian_adams_summer_69.append([2,0,0,0,2,0,0,2])\n",
        "\n",
        "brian_adams_summer_69.append([2,0,0,0,0,0,0,2])\n",
        "brian_adams_summer_69.append([2,0,0,0,2,0,0,0])\n",
        "brian_adams_summer_69.append([2,0,0,0,0,0,0,2])\n",
        "brian_adams_summer_69.append([2,1,0,0,0,0,0,0])\n",
        "\n",
        "brian_adams_summer_69.append([2,0,0,0,2,0,0,0])\n",
        "brian_adams_summer_69.append([2,0,0,0,2,2,0,0])\n",
        "brian_adams_summer_69.append([2,0,0,0,2,0,0,0])\n",
        "brian_adams_summer_69.append([2,0,2,0,2,0,2,0])\n",
        "\n",
        "summer_69_simplified = simplify_song(brian_adams_summer_69)\n",
        "summer_69_simplified = np.array(summer_69_simplified)\n",
        "print(summer_69_simplified)\n",
        "file = open('training_data/ba_s69.txt', 'w')\n",
        "file.write(str(summer_69_simplified))\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqpiG2m3qPor"
      },
      "source": [
        "# Chorus of Smells Like Teenspirit by Nirvana\n",
        "# any notes that were 16ths are incooporated as 8th notes\n",
        "nirvana_smells_like_teenspirit = []\n",
        "for i in range(11):\n",
        "  nirvana_smells_like_teenspirit.append([2,2,0,0,2,2,0,2])\n",
        "nirvana_smells_like_teenspirit.append([2,2,0,2,0,2,0,2])\n",
        "\n",
        "nirvana_slts_simplified = simplify_song(nirvana_smells_like_teenspirit)\n",
        "nirvana_slts_simplified = np.array(nirvana_slts_simplified)\n",
        "print(nirvana_slts_simplified)\n",
        "file = open('training_data/nirvana_slts.txt', 'w')\n",
        "file.write(str(nirvana_slts_simplified))\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q26UJudSrRKj"
      },
      "source": [
        "# Chorus of Highway to Hell by AC/DC\n",
        "ACDC_highway_to_hell = []\n",
        "ACDC_highway_to_hell.append([2,0,0,0,2,0,0,2])\n",
        "ACDC_highway_to_hell.append([2,0,0,0,2,1,0,0])\n",
        "ACDC_highway_to_hell.append([2,0,0,0,2,0,0,2])\n",
        "ACDC_highway_to_hell.append([2,0,0,0,2,1,0,0])\n",
        "ACDC_highway_to_hell.append([2,0,0,0,2,0,0,2])\n",
        "ACDC_highway_to_hell.append([2,0,0,0,2,1,0,0])\n",
        "ACDC_highway_to_hell.append([2,0,0,0,2,0,0,2])\n",
        "ACDC_highway_to_hell.append([2,0,0,0,2,1,0,0])\n",
        "ACDC_highway_to_hell.append([2,0,0,0,2,0,0,2])\n",
        "ACDC_highway_to_hell.append([2,0,0,0,2,1,0,0])\n",
        "ACDC_highway_to_hell.append([2,0,0,0,2,0,0,0])\n",
        "ACDC_highway_to_hell.append([0,0,0,0,0,0,0,0])\n",
        "ACDC_highway_to_hell.append([0,0,0,0,0,0,0,2])\n",
        "\n",
        "ACDC_hth_simplified = simplify_song(ACDC_highway_to_hell)\n",
        "ACDC_hth_simplified = np.array(ACDC_hth_simplified)\n",
        "print(ACDC_hth_simplified)\n",
        "file = open('training_data/ACDC_hth.txt', 'w')\n",
        "file.write(str(ACDC_hth_simplified))\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_3lrWNu7Tcu"
      },
      "source": [
        "real_dataset = []\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "real_dataset.extend(bj_iml_updated)\n",
        "real_dataset.extend(queen_up_simplified)\n",
        "real_dataset.extend(eyeofthetiger_simplified)\n",
        "real_dataset.extend(arctic_rumine_simplified)\n",
        "real_dataset.extend(fob_takeover_breaksover_simplified)\n",
        "real_dataset.extend(nickelback_tihyrm_simplified)\n",
        "real_dataset.extend(brightside_simplified)\n",
        "real_dataset.extend(summer_69_simplified)\n",
        "real_dataset.extend(nirvana_slts_simplified)\n",
        "real_dataset.extend(ACDC_hth_simplified)\n",
        "\n",
        "real_dataset = np.array(real_dataset)\n",
        "real_dataset = np.reshape(real_dataset, (134, 8))\n",
        "\n",
        "X_train = []\n",
        "X_test =[]\n",
        "Y_train = []\n",
        "Y_test = []\n",
        "\n",
        "# The testing and training data isn't split between songs, \n",
        "# but rather summer of 69 is partly in both the testing and the training data\n",
        "# Because this is an extended lab exercise and many sequences are repeating, \n",
        "# we favoured having a nice percentual division between the training and \n",
        "# testing data over putting whole songs in it.\n",
        "X_train = real_dataset[0:102]\n",
        "Y_train = real_dataset[1:103]\n",
        "X_test = real_dataset[103:133]\n",
        "Y_test = real_dataset[104:134]\n",
        "\n",
        "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR7nXGmz9t8G"
      },
      "source": [
        "#The Network:\n",
        "Below we define the network architecture, we have 2 hidden layers of each 128 neurons, the input and output layer are both 8 neurons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paMsIyugutuu"
      },
      "source": [
        "# Fix the seed to ensure the results are replicable\n",
        "np.random.seed(24)\n",
        "tf.random.set_seed(24)\n",
        "\n",
        "# Initialize the MLP model\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "# The input layer, with the number of neurons is equal to the number\n",
        "# of data in X_train NumPy array (namely 8)\n",
        "model.add(\n",
        "    keras.layers.Dense(\n",
        "    name='InputLayer',\n",
        "    units=128,\n",
        "    input_dim=X_train.shape[1],           # This gives 8\n",
        "    kernel_initializer='glorot_uniform',  # defines how to initialise the weights  \n",
        "    # the regularization argument, minimizes Wx+b by adjusting W and b\n",
        "    activity_regularizer=tf.keras.regularizers.L1(1e-4),\n",
        "    bias_initializer='zeros',\n",
        "    activation='tanh') \n",
        ")\n",
        "# Hidden layer 1 with 128 neurons\n",
        "model.add(\n",
        "    keras.layers.Dense(\n",
        "    name='HiddenLayer1',\n",
        "    units=128,\n",
        "    input_dim=128,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    bias_initializer='zeros',\n",
        "    activity_regularizer=tf.keras.regularizers.L1(1e-4),\n",
        "    activation='tanh')\n",
        ")\n",
        "# Hidden layer 2 with 128 neurons\n",
        "model.add(\n",
        "    keras.layers.Dense(\n",
        "    name='HiddenLayer2',\n",
        "    units=128,\n",
        "    input_dim=128,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    bias_initializer='zeros',\n",
        "    activity_regularizer=tf.keras.regularizers.L1(1e-4),\n",
        "    activation='tanh')\n",
        ")\n",
        "\n",
        "# Add an output layer. The number of output layer neurons is equal to the number\n",
        "# of data in Y_train NumPy array (namely 8)\n",
        "model.add(\n",
        "    keras.layers.Dense(\n",
        "    name='OutputLayer',\n",
        "    units=Y_train.shape[1],\n",
        "    input_dim=128,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    bias_initializer='zeros',\n",
        "    activation='tanh')\n",
        ")\n",
        "\n",
        "# Define Stochastic Gradient Descent optimizer\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.005, momentum=0.3)\n",
        "# Compile model use Mean Square Error loss\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=[\"accuracy\", \"mse\"])\n",
        "# Train model (4000 epochs,each epoch model is tested on validation dataset.\n",
        "# Verbose=2 allows to see extra details for each epoch, 0 hides all progress.)\n",
        "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test),  epochs=4000, verbose=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFzFp6ioBUtV"
      },
      "source": [
        "# Generating the Results\n",
        "Below we generate the results and test them with our testing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-tCqcxyNOvT"
      },
      "source": [
        "import matplotlib.scale\n",
        "\n",
        "generator = [1, 1, 0, 0, 0, 1, 0, 1]\n",
        "generator = np.expand_dims(generator, axis=0)\n",
        "generatedDrum = generator\n",
        "\n",
        "pyplot.plot(history.history['accuracy'], label='train')\n",
        "pyplot.plot(history.history['val_accuracy'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.xlabel(\"Epochs\")\n",
        "pyplot.ylabel(\"Accuracy\")\n",
        "pyplot.show()\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "for i in range(8):\n",
        "  output = model.predict(generator, verbose=0)\n",
        "  output[output <= 0.5] = 0\n",
        "  output[output > 0.5] = 1\n",
        "  print(output)\n",
        "  \n",
        "  generatedDrum = np.append(generatedDrum, output)\n",
        "  generator = generatedDrum[-8:]\n",
        "  generator = np.expand_dims(generator, axis=0)\n",
        "  \n",
        "print(generatedDrum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNvRcbC7Fy8U"
      },
      "source": [
        "model.summary()\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61
        },
        "id": "Cb1yQ-sT-qJG",
        "outputId": "72b0beb4-388c-4576-fea0-f25c6cd448b6"
      },
      "source": [
        "from note_seq.protobuf import music_pb2\n",
        "np.random.seed(24)\n",
        "pitch_set = [36, 38, 40, 42]\n",
        "#pitch_set = [36]\n",
        "drums = music_pb2.NoteSequence()\n",
        "for i in range(0, len(generatedDrum)):\n",
        "  if i%8 == 0:\n",
        "    pitch_choice = 38\n",
        "  else: \n",
        "    pitch_choice = 36\n",
        "  if generatedDrum[i] != 0:\n",
        "    drums.notes.add(pitch=pitch_choice, start_time=0.27*i, end_time=(0.27*(i+1)), is_drum=True, instrument=10, velocity=110)\n",
        "\n",
        "drums.total_time = 0.27*len(generatedDrum)\n",
        "\n",
        "drums.tempos.add(qpm=90)\n",
        "\n",
        "# This is a colab utility method that plays a NoteSequence.\n",
        "note_seq.play_sequence(drums,synth=note_seq.fluidsynth)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id=\"id_1\"> </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1i6GDxTU6Pf"
      },
      "source": [
        "# Extra\n",
        "\n",
        "Below we do some extra analysis of the data, e.g., finding fixed points in the NN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGz7-LO3ABie"
      },
      "source": [
        "# This is a colab utility method that visualizes a NoteSequence.\n",
        "note_seq.plot_sequence(drums)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5TlhcXBspUp"
      },
      "source": [
        "def runNetwork(generator,length):\n",
        "  generator = np.expand_dims(generator, axis=0)\n",
        "  generatedDrum = generator\n",
        "  np.set_printoptions(precision=2)\n",
        "  for i in range(length):\n",
        "    output = model.predict(generator, verbose=0)\n",
        "  \n",
        "    output[output <= 0.5] = 0\n",
        "    output[output > 0.5] = 1\n",
        "    \n",
        "    generatedDrum = np.append(generatedDrum, output)\n",
        "    generator = generatedDrum[-8:]\n",
        "    generator = np.expand_dims(generator, axis=0)\n",
        "  if length == 1:\n",
        "    return generator\n",
        "  return generatedDrum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odBJhrxxsLFK"
      },
      "source": [
        "file = open('fixed_points.txt', 'w')\n",
        "unconverging_points = []\n",
        "attractors = []\n",
        "fixed_points = 0\n",
        "fixed_points_list = []\n",
        "for a in range(2):\n",
        "  for b in range(2):\n",
        "    for c in range(2):\n",
        "      for d in range(2):\n",
        "        for e in range(2):\n",
        "          for f in range(2):\n",
        "            for g in range(2):\n",
        "              for h in range(2):\n",
        "                new_result = runNetwork([a,b,c,d,e,f,g,h],1)\n",
        "                result = np.expand_dims([a,b,c,d,e,f,g,h], axis=0)\n",
        "                iterations = 0\n",
        "                while not np.array_equal(new_result,result):\n",
        "                  result = new_result\n",
        "                  if iterations == 100:\n",
        "                    unconverging_points.append([a,b,c,d,e,f,g,h])\n",
        "                    break\n",
        "                  iterations += 1\n",
        "                  new_result = runNetwork(result[0],1)  \n",
        "                if iterations<100:\n",
        "                  print(\"After \", iterations, \" iterations \", [a,b,c,d,e,f,g,h], \" ended up in fixed point \", new_result[0])\n",
        "                  attractors.append(new_result[0])\n",
        "                  fixed_points_list.append(new_result[0])\n",
        "                  file.write(\"After \" + str(iterations) + \" iterations \" + str([a,b,c,d,e,f,g,h])+ \" ended up in fixed point \"+ str(new_result[0]) +'\\n')\n",
        "                #if np.array_equal(np.expand_dims([a,b,c,d,e,f,g,h], axis=0),result):\n",
        "                #  print(\"Fixed point:\" , [a,b,c,d,e,f,g,h], ' | ', result[0])\n",
        "                #  fixed_points+=1\n",
        "                #else:\n",
        "                #  print(\"Not a fixed point: \", [a,b,c,d,e,f,g,h], ' | ', result[0])\n",
        "#print(\"The number of fixed points is: \", fixed_points)\n",
        "for point in unconverging_points:\n",
        "  print(\"No fixed point in 100 iterations for: \", point)\n",
        "  file.write(\"No fixed point in 100 iterations for: \"+ str(point) + '\\n')\n",
        "  result = runNetwork(point,10)\n",
        "  print(result)\n",
        "  results_string = \"\"\n",
        "  for i in range(len(result)):\n",
        "    if i % 8 == 0:\n",
        "      results_string += \"| \"\n",
        "    results_string += str(result[i]) + \" \"\n",
        "  print(results_string)\n",
        "  file.write(results_string + '\\n')\n",
        "file.close()\n",
        "print(len(unconverging_points))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSWvlizPE96p"
      },
      "source": [
        "print(str(attractors))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5rQItE21p4w"
      },
      "source": [
        "#print(str(fixed_points_list))\n",
        "#here we consider each bar as a binary code, which we store in its decimal representation\n",
        "histogram = np.zeros(pow(2,8))\n",
        "test = []\n",
        "for point in fixed_points_list:\n",
        "  point_value = 0\n",
        "  \n",
        "  for i in range(len(point)):\n",
        "    point_value += point[i]*pow(2,(len(point)-i-1))\n",
        "  \n",
        "  histogram[int(point_value)] +=1\n",
        "  test.append(point_value)\n",
        "#print(histogram)\n",
        "fig, ax = pyplot.subplots(figsize =(10, 7))\n",
        "ax.hist(test, bins = list(range(120,260)))\n",
        "pyplot.xlabel(\"Decimal representation of the bars\")\n",
        "pyplot.ylabel(\"Number of times a sequence of bars converges to the bar\")\n",
        "plt.show()\n",
        "\n",
        "# found on https://www.geeksforgeeks.org/python-program-to-covert-decimal-to-binary-number/\n",
        "def decimalToBinary(n):\n",
        "    return bin(n).replace(\"0b\", \"\")\n",
        "\n",
        "i = 0\n",
        "for x in histogram:\n",
        "  if x != 0:\n",
        "    print(\"point \"+str(decimalToBinary(i))+ \" occurred \"+ str(x) + \" times.\")\n",
        "  i+=1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}